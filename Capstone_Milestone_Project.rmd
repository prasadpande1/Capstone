---
title: "Capstone Milestone Project"
author: "Prasad P"
date: "26 November 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(stringi)
library(ngram)
library(tm)
library(quanteda)
library(plyr)
library(RWeka)
```

## Reading files 

```{r readfiles}
# Read blogs file
blog_file <- file.info("C:/Users/prasad.pande/Documents/R- Assignment/Capstone/final/en_US/en_US.blogs.txt")
con1 <-file("C:/Users/prasad.pande/Documents/R- Assignment/Capstone/final/en_US/en_US.blogs.txt")
num_lines_blog <- readLines(con1,encoding = "UTF-8", skipNul = TRUE)


# Read twitter file
twtr_file <- file.info("C:/Users/prasad.pande/Documents/R- Assignment/Capstone/final/en_US/en_US.twitter.txt")
con2 <-file("C:/Users/prasad.pande/Documents/R- Assignment/Capstone/final/en_US/en_US.twitter.txt")
num_lines_twtr <- readLines(con2,encoding = "UTF-8", skipNul = TRUE)

# Read news file
news_file <- file.info("C:/Users/prasad.pande/Documents/R- Assignment/Capstone/final/en_US/en_US.news.txt")

num_lines_news <- readLines(con3 <- file("C:/Users/prasad.pande/Documents/R- Assignment/Capstone/final/en_US/en_US.news.txt"), skipNul = TRUE)

# Calculating the file sizein MB
file_size <- round(c(blog_file$size/1024^2, twtr_file$size/1024^2,news_file$size/1024^2))
# Calculating the lines in each file
lines_count <- sapply(list(num_lines_blog,num_lines_twtr, num_lines_news), length)
# Calculating the words in each file
words_count <- c(wordcount(num_lines_blog, sep = " "),wordcount(num_lines_twtr, sep = " "),wordcount(num_lines_news, sep = " "))
# Calculating the words in each line
words_per_line <- round(words_count/lines_count)

#Overall summary of the files
summary <- data.frame(file=c("Blogs","Twitter", "News"), file_size,lines_count,words_count,words_per_line)



blogS <- sample(num_lines_blog, lines_count[1]*0.01, replace = T)

#corpus <- Corpus(VectorSource(blogS))
text.corpus <- tm::Corpus(VectorSource(blogS))

# other transformations
text.corpus <- tm::tm_map(text.corpus, content_transformer(tolower))
text.corpus <- tm::tm_map(text.corpus, removeNumbers)
# cursewords file loaded locally
#text.corpus <- tm::tm_map(text.corpus, removeWords, cursewords)
#text.corpus <- tm::tm_map(text.corpus, content_transformer(removeURL))
text.corpus <- tm::tm_map(text.corpus, removePunctuation)
text.corpus <- tm::tm_map(text.corpus, removeWords, stopwords("english"))

blogtdm <- tm::TermDocumentMatrix(text.corpus, control = list(wordLengths = c(3,Inf)))
blogtdm_1 <- subset(rowSums(as.matrix(blogtdm)),rowSums(as.matrix(blogtdm))>500)

blogtdm_df <- data.frame(term = names(blogtdm_1), freq = blogtdm_1)
#########
#######
bi_tokenizer <- function(x) RWeka::NGramTokenizer(x, Weka_control(min=3, max=3))
blogtdm2 <- tm::TermDocumentMatrix(text.corpus, control = list(tokenize = bi_tokenizer))
blogtdm_2 <- subset(rowSums(as.matrix(blogtdm2)),rowSums(as.matrix(blogtdm2))>500)
blogtdm_df2 <- data.frame(term = names(blogtdm_2), freq = blogtdm_2)

blogtdm_freq_2 <- findFreqTerms(blogtdm2, lowfreq = 25)

blogtdm_2 <- subset(rowSums(as.matrix(blogtdm2)),rowSums(as.matrix(blogtdm2))>20)



###**************
blogtdm_df2 <- data.frame(term = names(blogtdm_2), freq = blogtdm_2)

blogtdm <- tm::TermDocumentMatrix(text.corpus, control = list(tokenize = BigramTokenizer))
require(reshape2)
blogtdm$dimnames$Terms <- rownames(blogtdm$dimnames)
melt(blogtdm$dimnames)
Freq.blog <- data.frame(word = blogtdm$dimnames$Terms, frequency=blogtdm$v)

#corpus <- gsub("[^A-Za-z//']","'", corpus, ignore.case = TRUE)
#corpus <- tm_map(corpus, tolower)

#suppressMessages(wordcloud(corpus, max.words = 500))

ngramsparse <- dfm(corpus, ngrams=1, concatenator = " ")
ngarm1 <- ngram(corpus, 1)

uni_tokenizer <- function(x) NGramTokenizer(x, Weka_control(min=1, max=1))
uni_matrix <- TermDocumentMatrix(corpus, control=list(tokenize = uni_tokenizer))

```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
